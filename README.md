![Twinkle Eval](assets/logo.png)

# ğŸŒŸ Twinkle Evalï¼šé«˜æ•ˆä¸”æº–ç¢ºçš„ AI è©•æ¸¬å·¥å…·

[![Python](https://img.shields.io/badge/python-â‰¥3.10-blue.svg?logo=python)](https://www.python.org)
![Project Status](https://img.shields.io/badge/status-active-brightgreen)
![Platform](https://img.shields.io/badge/platform-Windows%20|%20Linux-blue)

![GitHub license](https://img.shields.io/github/license/ai-twinkle/Eval)
![GitHub issues](https://img.shields.io/github/issues/ai-twinkle/Eval)
![GitHub stars](https://img.shields.io/github/stars/ai-twinkle/Eval?style=social)
![GitHub forks](https://img.shields.io/github/forks/ai-twinkle/Eval?style=social)
[![GitHub pull request](https://img.shields.io/badge/PRs-welcome-blue)](https://github.com/ai-twinkle/Eval/pulls)

![GitHub last commit](https://img.shields.io/github/last-commit/ai-twinkle/Eval)
![GitHub repo size](https://img.shields.io/github/repo-size/ai-twinkle/Eval)
![GitHub top language](https://img.shields.io/github/languages/top/ai-twinkle/Eval)
![GitHub languages](https://img.shields.io/github/languages/count/ai-twinkle/Eval)

[![Discord](https://img.shields.io/discord/1310544431983759450?label=Twinkle%20AI&logo=discord&style=for-the-badge)](https://discord.gg/Cx737yw4ed)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—%20Visit%20Huggingface-twinkle--ai-blue?style=for-the-badge)](https://huggingface.co/twinkle-ai)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Visit%20My%20Profile-blue?logo=linkedin&style=flat)](https://linkedin.com/company/twinkle-ai)

[![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-orange?logo=google-colab&style=for-the-badge)](https://colab.research.google.com/github/LiuYuWei/llm-colab-application/blob/main/Simon_LLM_Application_Twinkle_Eval_Tool_Google_Gemini_Model_Evaluation.ipynb)

æœ¬å°ˆæ¡ˆç‚º LLMï¼ˆLarge Language Modelï¼‰è©•æ¸¬æ¡†æ¶ï¼Œæ¡ç”¨ä¸¦è¡Œä¸”éš¨æ©ŸåŒ–æ¸¬è©¦æ–¹æ³•ï¼Œæä¾›å®¢è§€çš„æ¨¡å‹æ€§èƒ½åˆ†æèˆ‡ç©©å®šæ€§è©•ä¼°ï¼Œä¸¦æ”¯æ´å¤šç¨®å¸¸è¦‹è©•æ¸¬æ•¸æ“šé›†ã€‚
> ğŸ“– **[Twinkle Eval å¯å°è©±å¼ç¶­åŸºç™¾ç§‘é é¢ï¼ˆç”± DeepWiki ç”Ÿæˆï¼‰](https://deepwiki.com/ai-twinkle/Eval)**  
> å‚™è¨»ï¼šå…§å®¹ç”±äººå·¥æ™ºæ…§ç”Ÿæˆï¼Œæº–ç¢ºæ€§ç„¡æ³•ä¿è­‰ï¼Œåƒ…ä¾›åƒè€ƒã€‚

## ç›®éŒ„

- [åŠŸèƒ½ç‰¹è‰²](#åŠŸèƒ½ç‰¹è‰²)
- [æ€§èƒ½æŒ‡æ¨™](#æ€§èƒ½æŒ‡æ¨™)
- [æŠ€è¡“ç‰¹é»](#æŠ€è¡“ç‰¹é»)
  - [è©•æ¸¬æ–¹æ³•](#è©•æ¸¬æ–¹æ³•)
  - [æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†](#æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†)
  - [API æ•ˆèƒ½è¨­å®š](#api-æ•ˆèƒ½è¨­å®š)
- [å®‰è£è¨­å®š](#å®‰è£è¨­å®š)
- [ä½¿ç”¨æ–¹å¼](#ä½¿ç”¨æ–¹å¼)
  - [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
  - [å‘½ä»¤åˆ—é¸é …](#å‘½ä»¤åˆ—é¸é …)
  - [Python API ä½¿ç”¨](#python-api-ä½¿ç”¨)
- [ç¨‹å¼ç¢¼æ¶æ§‹](#ç¨‹å¼ç¢¼æ¶æ§‹)
- [è¨­å®šæª”èªªæ˜](#è¨­å®šæª”èªªæ˜)
  - [LLM API è¨­å®š](#llm-api-è¨­å®š)
  - [æ¨¡å‹è¨­å®š](#æ¨¡å‹è¨­å®š)
  - [è©•æ¸¬è¨­å®š](#è©•æ¸¬è¨­å®š)
  - [æ—¥èªŒè¨­å®š](#æ—¥èªŒè¨­å®š)
- [è¼¸å‡ºçµæœ](#è¼¸å‡ºçµæœ)
- [æ¨¡å‹å¯¦æ¸¬çµæœ](#æ¨¡å‹å¯¦æ¸¬çµæœ)
- [è²¢ç»è€…](#è²¢ç»è€…)
- [æˆæ¬Šæ¢æ¬¾](#æˆæ¬Šæ¢æ¬¾)
- [å¼•ç”¨](#å¼•ç”¨)
- [è‡´è¬](#è‡´è¬)

## åŠŸèƒ½ç‰¹è‰²

- **è‡ªå‹•åŒ–è©•æ¸¬å¤šå€‹æª”æ¡ˆ**ï¼šå¯æ‰¹æ¬¡è™•ç†ä¸¦çµ±ä¸€ç”Ÿæˆè©•æ¸¬çµæœã€‚
- **å¯è‡ªè¨‚è©•æ¸¬åƒæ•¸èˆ‡ç”Ÿæˆæ§åˆ¶**ï¼šå¯è¨­å®šæº«åº¦ã€top_p ç­‰ç”Ÿæˆåƒæ•¸ã€‚
- **é¸é …éš¨æ©Ÿæ’åˆ—åŠŸèƒ½**ï¼šé¿å…æ¨¡å‹å› é¸é …é †åºç”¢ç”Ÿåå¥½ã€‚
- **Pattern æˆ– Box é›™æ¨¡å¼è©•æ¸¬**ï¼šæ”¯æ´æ–‡å­—åŒ¹é…æˆ–æ¡†é¸è©•åˆ†é‚è¼¯ã€‚
- **å¤šæ¬¡æ¸¬è©¦å¹³å‡åˆ†æ**ï¼šè¨­å®šæ¸¬è©¦å›åˆæ•¸ä»¥è§€å¯Ÿæ¨¡å‹è¡¨ç¾ç©©å®šæ€§ã€‚
- **è¨ˆç®—å¹³å‡æ­£ç¢ºç‡èˆ‡ç©©å®šæ€§æŒ‡æ¨™**ï¼šé‡åŒ–æ¨¡å‹ç­”é¡Œæº–ç¢ºåº¦èˆ‡æ³¢å‹•ç¨‹åº¦ã€‚
- **ç´€éŒ„ LLM æ¨è«–èˆ‡çµ±è¨ˆçµæœ**ï¼šç”¨æ–¼å¾ŒçºŒåˆ†ææ¨¡å‹åœ¨å„é¡é¡Œå‹çš„è¡¨ç¾ã€‚
- **æ”¯æ´ OpenAI API æ ¼å¼**ï¼šç›¸å®¹æ–¼å¸¸è¦‹çš„ GPT API è¼¸å…¥èˆ‡è¼¸å‡ºæ ¼å¼ã€‚
- **å®‰å…¨åœ°è™•ç† API é‡‘é‘°**ï¼šé¿å…é‡‘é‘°æš´éœ²æ–¼ç¨‹å¼ç¢¼æˆ–æ—¥èªŒä¸­ã€‚
- **API è«‹æ±‚é™æµæ§åˆ¶èˆ‡è‡ªå‹•é‡è©¦æ©Ÿåˆ¶**ï¼šæ¸›å°‘éŒ¯èª¤ç™¼ç”Ÿä¸¦æé«˜ API è«‹æ±‚æˆåŠŸç‡ã€‚
- **HuggingFace æ•´åˆ**ï¼šæ”¯æ´å°‡è©•æ¸¬çµæœè‡ªå‹•ä¸Šå‚³è‡³ HuggingFace Datasetï¼Œæ–¹ä¾¿åˆ†äº«èˆ‡è¿½è¹¤ã€‚

## æ€§èƒ½æŒ‡æ¨™

ä¸‹åœ–å±•ç¤ºäº†åœ¨ [ikala/tmmluplus](https://huggingface.co/datasets/ikala/tmmluplus) - **basic_medical_science**ï¼ˆå…± 954 é¡Œï¼‰å­ä»»å‹™ä¸Šï¼ŒTwinkle Eval èˆ‡ç¾æœ‰å·¥å…· [iKala/ievals](https://github.com/iKala/ievals) åœ¨ä¸‰ç¨®æ¨¡å‹ä¸‹çš„æ¨è«–æ™‚é–“æ¯”è¼ƒï¼š

![TMMLU è©•æ¸¬æ™‚é–“çµ±è¨ˆ](assets/tmmlu_eval_time_rounded_seconds.png)

- [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct) (éæ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **9.4 å€**ã€‚
- [deepseek-ai/DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) (æ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **16.9 å€**ã€‚
- [mistralai/Mistral-Small-24B-Instruct-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501) (éæ¨ç†ä»»å‹™)ï¼šTwinkle Eval å¿«äº† **14.5 å€**ã€‚

é€™é …å¯¦é©—çµæœé¡¯ç¤ºï¼Œ**Twinkle Eval åœ¨ä¸åŒæ¨¡å‹å¤§å°èˆ‡ä»»å‹™é¡å‹ä¸‹çš†èƒ½é¡¯è‘—æå‡æ•ˆèƒ½ï¼Œæœ€é«˜é”è¿‘ 17 å€é€Ÿåº¦å„ªå‹¢**ï¼ŒåŒæ™‚ä¿æŒæº–ç¢ºç‡ä¸€è‡´ã€‚é€™å°æ–¼éœ€è¦å¤§é‡è©•æ¸¬çš„ LLM é–‹ç™¼å·¥ä½œæµç¨‹ï¼Œèƒ½å¤§å¹…ç¸®çŸ­é€±æœŸã€ç¯€çœæˆæœ¬ã€‚

## æŠ€è¡“ç‰¹é»

### è©•æ¸¬æ–¹æ³•

- **éš¨æ©ŸåŒ–æ¸¬è©¦**ï¼šåƒè€ƒ [Changing Answer Order Can Decrease MMLU Accuracy](https://arxiv.org/html/2406.19470v1)ï¼Œå¯¦ä½œ**é¸é …éš¨æ©Ÿæ’åˆ—åŠŸèƒ½**ï¼Œæ›´èƒ½å®¢è§€çš„è©•ä¼°æ¨¡å‹èƒ½åŠ›ã€‚
- **ç©©å®šæ€§åˆ†æ**ï¼šæ”¯æ´å¤šæ¬¡æ¸¬è©¦ä¸¦é€²è¡Œçµ±è¨ˆåˆ†æã€‚
- **æ ¼å¼æ§åˆ¶**ï¼šæŒ‡å®š `\box{é¸é …}` æˆ– `\boxed{é¸é …}` ç­‰æ¡†é¸æ ¼å¼ï¼Œåš´æ ¼ç®¡ç†è¼¸å‡ºå‘ˆç¾æ¨£å¼ã€‚
- **éŒ¯èª¤è™•ç†**ï¼šè‡ªå‹•é‡è©¦èˆ‡è¶…æ™‚æ§åˆ¶æ©Ÿåˆ¶ã€‚

### æ”¯æ´æ ¼å¼åŠå¸¸è¦‹æ•¸æ“šé›†

ä»»ä½•ç¬¦åˆä»¥ä¸‹æ ¼å¼çš„ `.csv`ã€`.json`ã€`.jsonl` æˆ– `.parquet` æª”æ¡ˆï¼Œå…§å®¹éœ€åŒ…å«ä¸‹åˆ—æ¬„ä½æ ¼å¼ï¼ˆä¸é™æ–¼ TMMLU+ï¼‰ï¼š

```csv
  question,A,B,C,D,answer
```

ä»¥ä¸‹åˆ—å‡ºå·²çŸ¥è©•æ¸¬é›†ï¼š

- [TMMLU+](https://huggingface.co/datasets/ikala/tmmluplus)
- [MMLU](https://github.com/hendrycks/test)
- [tw-legal-benchmark-v1](https://huggingface.co/datasets/lianghsun/tw-legal-benchmark-v1)
- [Formosa-bench](https://huggingface.co/datasets/lianghsun/Formosa-bench)

### API æ•ˆèƒ½è¨­å®š

- è¨­å®šè«‹æ±‚é™æµï¼šç„¡é™åˆ¶æˆ–æŒ‡å®š QPSï¼ˆQueries Per Secondï¼‰æ•¸å€¼ã€‚
- è¶…æ™‚è¨­å®šã€‚
- å¯é¸æ˜¯å¦é€²è¡Œ SSL é©—è­‰ã€‚
- éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶ã€‚

## å®‰è£è¨­å®š

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ pip å®‰è£ï¼ˆæ¨è–¦ï¼‰

```bash
# å¾ PyPI å®‰è£ï¼ˆç©©å®šç‰ˆæœ¬ï¼‰
pip install twinkle-eval

# æˆ–å¾ GitHub å®‰è£ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
pip install git+https://github.com/ai-twinkle/Eval.git
```

### æ–¹æ³•äºŒï¼šå¾åŸå§‹ç¢¼å®‰è£

1. è¤‡è£½å°ˆæ¡ˆè‡³æœ¬æ©Ÿ
   ```bash
   git clone https://github.com/ai-twinkle/Eval.git
   cd Eval
   ```

2. å®‰è£å¥—ä»¶
   ```bash
   # å®‰è£æ­£å¼ç‰ˆæœ¬
   pip install .
   
   # æˆ–å®‰è£é–‹ç™¼ç‰ˆæœ¬ï¼ˆåŒ…å«é–‹ç™¼å·¥å…·ï¼‰
   pip install -e ".[dev]"
   ```

## ä½¿ç”¨æ–¹å¼

### å¿«é€Ÿé–‹å§‹

1. å®‰è£å®Œæˆå¾Œï¼Œå‰µå»ºé…ç½®æª”æ¡ˆï¼š
   ```bash
   # ä½¿ç”¨å…§å»ºå‘½ä»¤å‰µå»ºé è¨­é…ç½®æª”æ¡ˆ
   twinkle-eval --init
   
   # ç·¨è¼¯é…ç½®æª”æ¡ˆ
   nano config.yaml
   ```

2. æº–å‚™è©•æ¸¬è³‡æ–™é›†ï¼š
   ```bash
   mkdir datasets
   # å°‡æ‚¨çš„è³‡æ–™é›†æª”æ¡ˆæ”¾å…¥ datasets ç›®éŒ„
   ```

3. åŸ·è¡Œè©•æ¸¬ï¼š
   ```bash
   twinkle-eval --config config.yaml
   ```

### å‘½ä»¤åˆ—é¸é …

å®‰è£å®Œæˆå¾Œï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `twinkle-eval` å‘½ä»¤ï¼š

```bash
# å‰µå»ºé è¨­é…ç½®æª”æ¡ˆ
twinkle-eval --init

# ä½¿ç”¨é è¨­é…ç½®åŸ·è¡Œè©•æ¸¬
twinkle-eval

# ä½¿ç”¨è‡ªå®šç¾©é…ç½®æª”æ¡ˆ
twinkle-eval --config path/to/your/config.yaml

# åŒæ™‚è¼¸å‡ºå¤šç¨®æ ¼å¼çš„çµæœ
twinkle-eval --export json csv html

# åˆ—å‡ºæ”¯æ´çš„ LLM é¡å‹
twinkle-eval --list-llms

# åˆ—å‡ºæ”¯æ´çš„è©•æ¸¬ç­–ç•¥
twinkle-eval --list-strategies

# åˆ—å‡ºæ”¯æ´çš„è¼¸å‡ºæ ¼å¼
twinkle-eval --list-exporters

# é¡¯ç¤ºç‰ˆæœ¬è³‡è¨Š
twinkle-eval --version

# é¡¯ç¤ºå®Œæ•´å¹«åŠ©
twinkle-eval --help

# è©•æ¸¬ä¸¦ä¸Šå‚³çµæœè‡³ HuggingFaceï¼ˆrepo ä¸å­˜åœ¨æœƒè‡ªå‹•å‰µå»ºï¼‰
twinkle-eval --config config.yaml \
  --hf-repo-id my-org/my-benchmark-logs-and-scores

# ä½¿ç”¨ variant å€åˆ†ä¸åŒè©•æ¸¬æ¢ä»¶
twinkle-eval --config config.yaml \
  --hf-repo-id my-org/my-benchmark-logs-and-scores \
  --hf-variant high-temperature

# çµåˆå¤šç¨®è¼¸å‡ºæ ¼å¼èˆ‡ HuggingFace ä¸Šå‚³
twinkle-eval --config config.yaml \
  --export json csv html \
  --hf-repo-id my-org/my-benchmark-logs-and-scores \
  --hf-variant baseline
```

**HuggingFace ä¸Šå‚³æ³¨æ„äº‹é …**ï¼š
- Repo ID æ ¼å¼ï¼š`namespace/repo-name`ï¼ˆrepo-name å¿…é ˆä»¥ `-logs-and-scores` çµå°¾ï¼‰
- éœ€è¦å…ˆç™»å…¥ï¼š`hf auth login` æˆ–è¨­å®š `HF_TOKEN` ç’°å¢ƒè®Šæ•¸
- Repo ä¸å­˜åœ¨æ™‚æœƒè‡ªå‹•å‰µå»ºç‚ºå…¬é–‹ dataset
- å·²å­˜åœ¨çš„æª”æ¡ˆä¸æœƒè¢«è¦†è“‹
- ä¸Šå‚³è·¯å¾‘ï¼š`results/<model_name>/<variant>/`

### Python API ä½¿ç”¨

æ‚¨ä¹Ÿå¯ä»¥åœ¨ Python ç¨‹å¼ä¸­ç›´æ¥ä½¿ç”¨ Twinkle Evalï¼š

```python
from twinkle_eval import TwinkleEvalRunner

# å»ºç«‹è©•æ¸¬åŸ·è¡Œå™¨
runner = TwinkleEvalRunner("config.yaml")

# åˆå§‹åŒ–
runner.initialize()

# æ–¹å¼ä¸€ï¼šåƒ…åŸ·è¡Œè©•æ¸¬
results = runner.run_evaluation(export_formats=["json", "csv"])

# æ–¹å¼äºŒï¼šåŸ·è¡Œè©•æ¸¬ä¸¦ä¸Šå‚³è‡³ HuggingFaceï¼ˆäºŒé¸ä¸€ï¼‰
# results = runner.run_evaluation(
#     export_formats=["json", "csv"],
#     hf_repo_id="my-org/my-benchmark-logs-and-scores",
#     hf_variant="baseline"
# )

print(f"è©•æ¸¬å®Œæˆï¼çµæœå·²å„²å­˜è‡³ï¼š{results}")
```

è©•æ¸¬çµæœæœƒå„²å­˜åœ¨ `results` ç›®éŒ„ä¸­ï¼Œæª”ååŒ…å«æ™‚é–“æˆ³è¨˜ã€‚

## ç¨‹å¼ç¢¼æ¶æ§‹

é‡æ§‹å¾Œçš„ç¨‹å¼ç¢¼æ¡ç”¨æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡çµ„ï¼š

- **`config.py`**: é…ç½®ç®¡ç†ï¼Œè² è²¬è¼‰å…¥å’Œé©—è­‰é…ç½®æª”æ¡ˆ
- **`main.py`**: ä¸»ç¨‹å¼å…¥å£é»ï¼Œè™•ç†å‘½ä»¤åˆ—ä»‹é¢å’Œè©•æ¸¬æµç¨‹æ§åˆ¶
- **`models.py`**: LLM æŠ½è±¡å±¤ï¼Œæ”¯æ´å¤šç¨® LLM APIï¼ˆç›®å‰æ”¯æ´ OpenAI ç›¸å®¹æ ¼å¼ï¼‰
- **`datasets.py`**: è³‡æ–™é›†è¼‰å…¥å’Œè™•ç†ï¼Œæ”¯æ´ JSONã€JSONLã€CSVã€TSVã€Parquet æ ¼å¼
- **`evaluators.py`**: è©•æ¸¬æ ¸å¿ƒé‚è¼¯ï¼ŒåŒ…å«ä¸¦è¡Œè™•ç†å’Œé€²åº¦è¿½è¹¤
- **`evaluation_strategies.py`**: ç­”æ¡ˆæå–ç­–ç•¥ï¼ŒåŒ…å« Patternã€Boxã€è‡ªå®šç¾©æ­£å‰‡ä¸‰ç¨®ç­–ç•¥
- **`results_exporters.py`**: çµæœè¼¸å‡ºæ¨¡çµ„ï¼Œæ”¯æ´ JSONã€CSVã€HTML ç­‰æ ¼å¼
- **`validators.py`**: é©—è­‰å·¥å…·ï¼Œç¢ºä¿é…ç½®å’Œè³‡æ–™é›†çš„æ­£ç¢ºæ€§
- **`exceptions.py`**: è‡ªå®šç¾©ç•°å¸¸é¡åˆ¥ï¼Œæä¾›ç²¾ç¢ºçš„éŒ¯èª¤è™•ç†

é€™ç¨®æ¨¡çµ„åŒ–è¨­è¨ˆè®“ç¨‹å¼ç¢¼æ›´å®¹æ˜“ç¶­è­·å’Œæ“´å±•ï¼Œé–‹ç™¼è€…å¯ä»¥è¼•é¬†ï¼š
- æ–°å¢æ”¯æ´æ–°çš„ LLM API
- å¯¦ç¾æ–°çš„ç­”æ¡ˆæå–ç­–ç•¥
- å¢åŠ æ–°çš„è¼¸å‡ºæ ¼å¼
- æ”¹é€²é©—è­‰é‚è¼¯

## è¨­å®šæª”èªªæ˜

è¨­å®šæª”ä½¿ç”¨ YAML æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦å€æ®µï¼š

### LLM API è¨­å®š

```yaml
llm_api:
  base_url: "http://your-openai-compatible-server/v1" # API ä¼ºæœå™¨ç¶²å€
  api_key: "your-api-key" # API é‡‘é‘°
  disable_ssl_verify: false # æ˜¯å¦åœç”¨ SSL é©—è­‰
  api_rate_limit: 2 # æ¯ç§’è«‹æ±‚é™åˆ¶ï¼ˆ-1 ç‚ºä¸é™åˆ¶ï¼‰
  max_retries: 5 # API å‘¼å«å¤±æ•—æ™‚çš„é‡è©¦æ¬¡æ•¸
  timeout: 600 # API å‘¼å«çš„è¶…æ™‚æ™‚é–“ (ç§’)
```

### æ¨¡å‹è¨­å®š

```yaml
model:
  name: "model-name" # æ¨¡å‹åç¨±
  temperature: 0.0 # æº«åº¦åƒæ•¸
  top_p: 0.9 # Top-p æ©Ÿç‡é–¾å€¼
  max_tokens: 4096 # æœ€å¤§è¼¸å‡º token æ•¸
  frequency_penalty: 0.0 # é »ç‡æ‡²ç½°
  presence_penalty: 0.0 # å­˜åœ¨æ‡²ç½°
```

### è©•æ¸¬è¨­å®š

```yaml
evaluation:
  dataset_paths: # è³‡æ–™é›†è·¯å¾‘
    - "datasets/dataset1/"
    - "datasets/dataset2/"
  evaluation_method: "box" # è©•æ¸¬æ–¹æ³•ï¼ˆæ”¯æ´ "pattern" æˆ– "box"ï¼‰
  system_prompt:        # ç³»çµ±æç¤ºè©ï¼Œåƒ…æ–¼ box è©•æ¸¬æ–¹æ³•ä¸­ä½¿ç”¨
    zh: |
      ä½¿ç”¨è€…å°‡æä¾›ä¸€å€‹é¡Œç›®ï¼Œä¸¦é™„ä¸Šé¸é … Aã€Bã€Cã€D
      è«‹ä»”ç´°é–±è®€é¡Œç›®è¦æ±‚ï¼Œæ ¹æ“šé¡Œæ„é¸å‡ºæœ€ç¬¦åˆçš„é¸é …ï¼Œä¸¦å°‡é¸é …ä»¥ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š
      \box{é¸é …}
      è«‹ç¢ºä¿åƒ…å°‡é¸é …åŒ…å«åœ¨ { } ä¸­ï¼Œå¦å‰‡å°‡ä¸è¨ˆç®—ç‚ºæœ‰æ•ˆç­”æ¡ˆã€‚
      å‹™å¿…ç²¾ç¢ºéµå¾ªè¼¸å‡ºæ ¼å¼ï¼Œé¿å…ä»»ä½•å¤šé¤˜å…§å®¹æˆ–éŒ¯èª¤æ ¼å¼ã€‚
    en: |
      The user will provide a question along with options A, B, C, and D.
      Please read the question carefully and select the option that best fits the requirements.
      Output the selected option in the following format:
      \box{Option}
      Make sure to include only the option within the curly braces; otherwise, it will not be considered a valid answer.
      Strictly follow the output format and avoid any extra content or incorrect formatting.
  datasets_prompt_map:
    "datasets/mmlu/": "en" # æŒ‡å®šè³‡æ–™é›†ä½¿ç”¨è‹±æ–‡æç¤ºè©
  repeat_runs: 5 # å–®ä¸€ datasets é‡è¤‡åŸ·è¡Œæ¬¡æ•¸
  shuffle_options: true # æ˜¯å¦å°é¸é …é€²è¡Œéš¨æ©Ÿæ’åº
```

### æ—¥èªŒè¨­å®š

```yaml
logging:
  level: "INFO" # æ—¥èªŒç­‰ç´šï¼ˆå¯é¸ DEBUG, INFO, WARNING, ERRORï¼‰
```

## è¼¸å‡ºçµæœ

æœ¬å°ˆæ¡ˆè¼¸å‡ºå…©ä»½çµæœï¼Œåˆ†åˆ¥ç‚º `results_{timestamp}.json` èˆ‡ `eval_results_{timestamp}.json`ã€‚

### `results_{timestamp}.json`

é€™å€‹æª”æ¡ˆä¸»è¦ç”¨ä¾†**çµ±æ•´æ•´ä»½è©•æ¸¬çš„æ‘˜è¦è³‡è¨Š**ï¼Œé©åˆï¼š

- å¿«é€ŸæŸ¥çœ‹æ¨¡å‹åœ¨å¤šä»½è³‡æ–™é›†ä¸Šçš„è¡¨ç¾
- å°æ¯”ä¸åŒæ¨¡å‹ã€è¨­å®šçš„å¹³å‡æº–ç¢ºç‡
- å°ç…§ä½¿ç”¨çš„æ¨¡å‹åƒæ•¸ã€API è¨­å®š
- å¯æ­é… timestamp ä½œç‚ºè©•æ¸¬ç‰ˆæœ¬æ§åˆ¶ç´€éŒ„ä¾æ“š

```json
{
  "timestamp": "20250314_1158", // è©•æ¸¬åŸ·è¡Œçš„æ™‚é–“æˆ³è¨˜
  "results": [
    // å„å€‹æ¸¬è©¦æª”æ¡ˆçš„è©•æ¸¬çµæœ
    {
      "file": "datasets/test/basic_medical_science_train.csv", // æ¸¬è©¦æª”æ¡ˆè·¯å¾‘
      "accuracy": 0.4 // æ¨¡å‹åœ¨è©²æª”æ¡ˆä¸Šçš„æ­£ç¢ºç‡
    },
    {
      "file": "datasets/test/culinary_skills_dev.csv",
      "accuracy": 0.4
    }
  ],
  "average_accuracy": 0.4, // æ‰€æœ‰è³‡æ–™é›†çš„å¹³å‡æ­£ç¢ºç‡
  "config": {
    "llm_api": {
      "base_url": "http://localhost:8002/v1/", // å‘¼å«æ¨¡å‹çš„ API ç«¯é»
      "api_key": "EMPTY" // API é‡‘é‘°ï¼ˆæ­¤è™•ç‚ºç©ºï¼‰
    },
    "model": {
      "name": "checkpoint-108", // ä½¿ç”¨çš„æ¨¡å‹åç¨±
      "temperature": 0, // æº«åº¦åƒæ•¸ï¼ˆå½±éŸ¿éš¨æ©Ÿæ€§ï¼‰
      "top_p": 0.9, // Top-p æ¡æ¨£åƒæ•¸
      "max_tokens": 4096, // æœ€å¤§ç”Ÿæˆé•·åº¦
      "frequency_penalty": 0,
      "presence_penalty": 0
    },
    "evaluation": {
      "dataset_path": "datasets/test/", // è©•æ¸¬è³‡æ–™é›†ç›®éŒ„
      "api_concurrency": 40, // ä¸¦è¡Œè«‹æ±‚æ•¸ï¼ˆå½±éŸ¿æ¨è«–é€Ÿåº¦ï¼‰
      "evaluation_method": "box", // è©•æ¸¬æ–¹å¼ç‚º box æ¨¡å¼
      "system_prompt": { // ç³»çµ±æç¤ºè©
        "zh": "...", // ä¸­æ–‡æç¤ºè©
        "en": "..."  // è‹±æ–‡æç¤ºè©
      },
      "datasets_prompt_map": {
        "datasets/mmlu/": "en"
      }
    }
  },
  "logging": {
    "level": "INFO" // æ—¥èªŒç­‰ç´š
  }
}
```

### `eval_results_{timestamp}.json`

é€™å€‹æª”æ¡ˆç”¨ä¾†**è¨˜éŒ„å–®ä¸€æ¸¬è©¦æª”ä¸­æ¯ä¸€é¡Œçš„ç­”é¡Œç‹€æ³**ï¼Œé©åˆï¼š

- åˆ†æéŒ¯é¡Œã€äº†è§£æ¨¡å‹å‡ºéŒ¯çš„å‚¾å‘
- æ­é…è³‡æ–™è¦–è¦ºåŒ–ï¼ˆå¦‚ confusion matrixã€éŒ¯èª¤ç‡ç†±åœ–ï¼‰

```json
{
  "timestamp": "20250314_1158",  // è©•æ¸¬åŸ·è¡Œçš„æ™‚é–“æˆ³è¨˜
  "file": "datasets/test/basic_medical_science_train.csv",  // æ¸¬è©¦æª”æ¡ˆè·¯å¾‘
  "accuracy": 0.4,  // æ¨¡å‹åœ¨è©²æª”æ¡ˆä¸Šçš„æ•´é«”æ­£ç¢ºç‡

  "details": [  // æ¯é¡Œçš„è©•æ¸¬è©³æƒ…
    {
      "question_id": 0,  // é¡Œç›®ç·¨è™Ÿ
      "question": "ä¸‹åˆ—ä½•è€…åƒ…ä½æ–¼è…è‡Ÿçš®è³ªï¼ˆcortexï¼‰ï¼ŸA: ä¹³é ­ç®¡ ...",  // é¡Œç›®å…§å®¹èˆ‡é¸é …
      "correct_answer": "C",  // æ­£ç¢ºç­”æ¡ˆ
      "predicted_answer": "C",  // æ¨¡å‹é æ¸¬ç­”æ¡ˆ
      "is_correct": true  // é æ¸¬æ˜¯å¦æ­£ç¢º
    },
    {
      "question_id": 1,
      ...
    }
  ]
}
```

## æ¨¡å‹å¯¦æ¸¬çµæœ

> [!NOTE]
> æœ¬è¡¨å°‡éš¨æ™‚é–“æ›´æ–°æ¨¡å‹è©•æ¸¬åˆ†æ•¸

| æ¨¡å‹                                                                                                                          | è©•æ¸¬æ¨¡å¼ | TMMLU+(%)       | tw-legal(%)     | MMLU(%)         | æ¸¬è©¦æ¬¡æ•¸ | é¸é …æ’åº |
| ----------------------------------------------------------------------------------------------------------------------------- | -------- | --------------- | --------------- | --------------- | -------- | -------- |
| [meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8) | box      | 78.27 (Â±0.0130) | 61.40 (Â±0.0081) | 87.26 (Â±0.0085) | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-4-Scout-17B-16E-Instruct](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct)                 | box      | 67.71 (Â±0.0147) | 47.21 (Â±0.0045) | 83.31 (Â±0.0097) | 3        | éš¨æ©Ÿ     |
| [mistralai/Mistral-Small-24B-Instruct-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501)                 | box      | 56.15 (Â±0.0172) | 37.48 (Â±0.0098) | 74.61 (Â±0.0154) | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)                                   | box      | 15.49 (Â±0.0104) | 25.68 (Â±0.0200) | 6.90 (Â±0.0096)  | 3        | éš¨æ©Ÿ     |
| [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)                                   | pattern  | 35.85 (Â±0.0174) | 32.22 (Â±0.0023) | 59.33 (Â±0.0168) | 3        | éš¨æ©Ÿ     |
| [MediaTek-Research/Llama-Breeze2-3B-Instruct](https://huggingface.co/MediaTek-Research/Llama-Breeze2-3B-Instruct)             | pattern  | 40.32 (Â±0.0181) | 38.92 (Â±0.0193) | 55.37 (Â±0.0180) | 3        | éš¨æ©Ÿ     |
| [twinkle-ai/Llama-3.2-3B-F1-Instruct](https://huggingface.co/twinkle-ai/Llama-3.2-3B-F1-Instruct)                             | box      | 46.16 (Â±0.0198) | 34.92 (Â±0.0243) | 51.22 (Â±0.0206) | 3        | éš¨æ©Ÿ     |

## è²¢ç»è€…

[![Teds Lin](https://img.shields.io/badge/GitHub-Teds%20Lin-blue?logo=github)](https://github.com/teds-lin)
[![Liang Hsun Huang](https://img.shields.io/badge/GitHub-Huang%20Liang%20Hsun-blue?logo=github)](https://github.com/lianghsun)
[![Min Yi Chen](https://img.shields.io/badge/GitHub-Min%20Yi%20Chen-blue?logo=github)](https://github.com/cyc00518)
[![Dave Sung](https://img.shields.io/badge/GitHub-Dave%20Sung-blue?logo=github)](https://github.com/k1dav)

æœ¬å°ˆæ¡ˆç”± [Twinkle AI](https://github.com/ai-twinkle) èˆ‡ [APMIC](https://www.apmic.ai/) åˆä½œé–‹ç™¼ã€‚

## æˆæ¬Šæ¢æ¬¾

æœ¬å„²å­˜åº«çš„åŸå§‹ç¢¼ä¾ç…§ [MIT](https://github.com/ai-twinkle/Eval?tab=MIT-1-ov-file#readme) æˆæ¬Šæ¢æ¬¾é–‹æºã€‚

## å¼•ç”¨

å¦‚æœæ‚¨è¦ºå¾—æ­¤è©•æ¸¬å·¥å…·æœ‰å¹«åŠ©åˆ°ï¼Œè«‹å†ä¸åå¼•ç”¨å¦‚ä¸‹ï¼š

```bibtex
@misc{twinkle_eval,
  author       = {Teds Lin, Liang Hsun Huang, Min Yi Chen and Dave Sung},
  title        = {Twinkle Eval: An Efficient and Accurate AI Evaluation Tool.},
  year         = {2025},
  url          = {https://github.com/ai-twinkle/Eval},
  note         = {GitHub repository}
}
```

## è‡´è¬

åœ¨æœ¬å°ˆæ¡ˆçš„é–‹ç™¼éç¨‹ä¸­ï¼Œæˆ‘å€‘åƒè€ƒäº† [iKala/ievals](https://github.com/iKala/ievals) å°ˆæ¡ˆä¸­çš„æ¨¡å¼è¨­è¨ˆç†å¿µï¼Œè©²å°ˆæ¡ˆå°æˆ‘å€‘çš„è¨­è¨ˆæ–¹å‘æä¾›äº†å¯¶è²´çš„å•Ÿç™¼ï¼Œç‰¹æ­¤è‡´ä¸Šèª æ‘¯æ„Ÿè¬ã€‚
åŒæ™‚ä¹Ÿæ„Ÿè¬ [Simon Liu](https://simonliuyuwei-4ndgcf4.gamma.site/) æä¾›çš„ Colab [ç¤ºç¯„ç¯„ä¾‹](https://colab.research.google.com/github/LiuYuWei/llm-colab-application/blob/main/Simon_LLM_Application_Twinkle_Eval_Tool_Google_Gemini_Model_Evaluation.ipynb)ï¼Œå”åŠ©æˆ‘å€‘æ›´ç›´è§€åœ°å‘ˆç¾å·¥å…·çš„ä½¿ç”¨æ–¹å¼èˆ‡å¯¦éš›æ‡‰ç”¨å ´æ™¯ã€‚
